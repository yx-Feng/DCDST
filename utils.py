from pathlib import Path
import glob
import re
import numpy as np
import pandas as pd
from scipy.sparse.linalg import eigsh


# ç”Ÿæˆä¸€ä¸ªä¿å­˜ç›®å½•ï¼Œå¹¶ç¡®ä¿ç›®å½•åç§°å”¯ä¸€ï¼Œä¾‹å¦‚ runs/exp --> runs/exp{sep}0, runs/exp{sep}1 ...
def increment_path(path, exist_ok=True, sep=''):
    path = Path(path)  # è½¬æ¢ä¸ºè·¯å¾„å¯¹è±¡ï¼Œç¡®ä¿è·¨å¹³å°å…¼å®¹
    # å¦‚æœç›®å½•ä¸å­˜åœ¨æˆ–å­˜åœ¨ä¸”å…è®¸é‡ç”¨ï¼Œè¿”å›åŸè·¯å¾„
    if (path.exists() and exist_ok) or (not path.exists()):
        return str(path)
    else:
        dirs = glob.glob(f"{path}{sep}*")  # æŸ¥æ‰¾æ‰€æœ‰ç±»ä¼¼çš„è·¯å¾„
        matches = [re.search(rf"%s{sep}(\d+)" % path.stem, d) for d in dirs] # åŒ¹é…ç±»ä¼¼çš„ç›®å½•ï¼Œæå–æ•°å­—éƒ¨åˆ†
        i = [int(m.groups()[0]) for m in matches if m]  # è·å–åŒ¹é…çš„æ•°å­—ç´¢å¼•
        n = max(i) + 1 if i else 2  # å¦‚æœæœ‰åŒ¹é…é¡¹ï¼Œé€’å¢æœ€å¤§æ•°å­—ï¼›å¦åˆ™ä»2å¼€å§‹
        return f"{path}{sep}{n}"  # è¿”å›é€’å¢åçš„æ–°ç›®å½•è·¯å¾„

# åŠ è½½é‚»æ¥çŸ©é˜µA, ç”¨äºè¡¨ç¤ºPOIçš„é‚»æ¥å…³ç³»ï¼Œç»´åº¦=(node_num, node_num)
def load_graph_adj_matrix(path):
    A = np.loadtxt(path, delimiter=',')
    return A

# åŠ è½½è·ç¦»çŸ©é˜µD, ç”¨äºè¡¨ç¤ºPOIçš„è·ç¦»å…³ç³»ï¼Œç»´åº¦=(node_num, node_num)
def load_graph_dist_matrix(path):
    D = np.loadtxt(path, delimiter=',')
    return D

# åŠ è½½èŠ‚ç‚¹ç‰¹å¾çŸ©é˜µXï¼Œç»´åº¦=(node_num, 4)
def load_graph_node_features(path, feature1, feature2, feature3):
    df = pd.read_csv(path)
    X = df[[feature1, feature2, feature3]].to_numpy()
    return X

# è®¡ç®—æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µ
def calculate_laplacian_matrix(adj_mat, mat_type):
    n_vertex = adj_mat.shape[0] # å›¾çš„ç»“ç‚¹æ•°é‡
    # è¡Œåº¦çŸ©é˜µ
    deg_mat_row = np.asmatrix(np.diag(np.sum(adj_mat, axis=1)))
    # column sum
    # deg_mat_col = np.asmatrix(np.diag(np.sum(adj_mat, axis=0)))
    deg_mat = deg_mat_row

    adj_mat = np.asmatrix(adj_mat) # å°†adj_matè½¬æ¢ä¸ºçŸ©é˜µæ ¼å¼ä»¥ä¾¿äºçŸ©é˜µè¿ç®—
    id_mat = np.asmatrix(np.identity(n_vertex)) # å•ä½çŸ©é˜µ
    # ç»„åˆæ‹‰æ™®æ‹‰æ–¯çŸ©é˜µï¼ˆCombinatorial Laplacian Matrixï¼‰
    # L=Dâˆ’Aï¼Œå…¶ä¸­ğ·æ˜¯åº¦çŸ©é˜µ, ğ´æ˜¯é‚»æ¥çŸ©é˜µ
    if mat_type == 'com_lap_mat':
        com_lap_mat = deg_mat - adj_mat
        return com_lap_mat
    elif mat_type == 'wid_rw_normd_lap_mat':
        # ç”¨äºåˆ‡æ¯”é›ªå¤«å·ç§¯ï¼ˆChebyshev Convolutionï¼‰çš„åŠ å®½å½’ä¸€åŒ–éšæœºæ¸¸èµ°æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µ
        rw_lap_mat = np.matmul(np.linalg.matrix_power(deg_mat, -1), adj_mat) # è®¡ç®—éšæœºæ¸¸èµ°çŸ©é˜µD^(-1)*A
        rw_normd_lap_mat = id_mat - rw_lap_mat # å½’ä¸€åŒ–éšæœºæ¸¸èµ°çŸ©é˜µ
        lambda_max_rw = eigsh(rw_lap_mat, k=1, which='LM', return_eigenvectors=False)[0] # ä½¿ç”¨ç‰¹å¾å€¼åˆ†è§£è®¡ç®—æœ€å¤§ç‰¹å¾å€¼ï¼Œç”¨äºè°ƒæ•´çŸ©é˜µçš„èŒƒå›´
        wid_rw_normd_lap_mat = 2 * rw_normd_lap_mat / lambda_max_rw - id_mat # åŠ å®½çŸ©é˜µ
        return wid_rw_normd_lap_mat
    elif mat_type == 'hat_rw_normd_lap_mat':
        # ç”¨äºGCNå·ç§¯çš„åŠ å¸½å½’ä¸€åŒ–éšæœºæ¸¸èµ°æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µ
        wid_deg_mat = deg_mat + id_mat
        wid_adj_mat = adj_mat + id_mat
        hat_rw_normd_lap_mat = np.matmul(np.linalg.matrix_power(wid_deg_mat, -1), wid_adj_mat)
        return hat_rw_normd_lap_mat
    else:
        raise ValueError(f'ERROR: {mat_type} is unknown.')

# è®¡ç®—å¸¦æœ‰æ©ç ï¼ˆmaskï¼‰çš„å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰æŸå¤±
def maksed_mse_loss(input, target, mask_value=-1):
    # åˆ›å»ºä¸€ä¸ªæ©ç ï¼Œæ ‡è®°ç›®æ ‡å¼ é‡ä¸­å€¼ä¸ºmask_valueçš„éƒ¨åˆ†
    mask = target == mask_value
    # è®¡ç®—è¾“å…¥å’Œç›®æ ‡çš„å¹³æ–¹å·®ï¼Œå¿½ç•¥æ©ç éƒ¨åˆ†
    out = (input[~mask] - target[~mask]) ** 2
    loss = out.mean() # è®¡ç®—æŸå¤±å€¼çš„å‡å€¼
    return loss  # è¿”å›è®¡ç®—å‡ºçš„æŸå¤±

# è®¡ç®— Top-Kå‡†ç¡®ç‡
def top_k_acc_last_timestep(y_true_seq, y_pred_seq, k):
    y_true = y_true_seq[-1] # çœŸå®çš„POIåºåˆ—
    y_pred = y_pred_seq[-1] # æ¨¡å‹é¢„æµ‹çš„POIåºåˆ—
    top_k_rec = y_pred.argsort()[-k:][::-1] # å¯¹é¢„æµ‹POIè¿›è¡Œæ’åºï¼Œé€‰å–å‰Kä¸ªé¢„æµ‹POI
    
    # å¦‚æœçœŸå®çš„POIå‡ºç°åœ¨å‰Kä¸ªæ¨èçš„POIä¸­ï¼Œè¿”å›1ï¼Œå¦åˆ™è¿”å›0
    idx = np.where(top_k_rec == y_true)[0]
    if len(idx) != 0:
        return 1
    else:
        return 0

# è®¡ç®—å¹³å‡ç²¾åº¦ mAP = 1/rank+1, å³åœ¨å‰Kä¸ªæ¨èçš„POIä¸­ï¼ŒçœŸå®çš„ä¸‹ä¸€ä¸ªPOIçš„æ’åä½ç½®è¶Šé å‰ï¼Œæ¨¡å‹çš„æ€§èƒ½è¶Šå¥½
def mAP_metric_last_timestep(y_true_seq, y_pred_seq, k):
    # AP: area under PR curve
    # But in next POI rec, the number of positive sample is always 1. Precision is not well defined.
    # Take def of mAP from Personalized Long- and Short-term Preference Learning for Next POI Recommendation
    y_true = y_true_seq[-1]
    y_pred = y_pred_seq[-1]
    rec_list = y_pred.argsort()[-k:][::-1]
    r_idx = np.where(rec_list == y_true)[0]
    if len(r_idx) != 0:
        return 1 / (r_idx[0] + 1)
    else:
        return 0

# è®¡ç®—å‡å€¼å€’æ•°æ’å
def MRR_metric_last_timestep(y_true_seq, y_pred_seq):
    """ next poi metrics """
    # Mean Reciprocal Rank: Reciprocal of the rank of the first relevant item
    y_true = y_true_seq[-1]
    y_pred = y_pred_seq[-1]
    rec_list = y_pred.argsort()[-len(y_pred):][::-1]
    r_idx = np.where(rec_list == y_true)[0][0]
    return 1 / (r_idx + 1)

# æ–°å¢ NDCG ç›¸å…³å‡½æ•°
def dcg_score_last_timestep(y_true_seq, y_pred_seq, k):
    """ next poi metrics: DCG score at the last timestep """
    y_true_id = y_true_seq[-1]  # çœŸå®POI ID
    y_pred = y_pred_seq[-1]     # é¢„æµ‹åˆ†æ•°å‘é‡

    # ç”Ÿæˆç†æƒ³one-hotå‘é‡
    num_poi = y_pred.shape[0]
    y_true_onehot = np.zeros(num_poi)
    if y_true_id < num_poi:  # é˜²æ­¢IDè¶Šç•Œ
        y_true_onehot[y_true_id] = 1

    # è®¡ç®—é¢„æµ‹æ’åºçš„DCG
    order = np.argsort(y_pred)[::-1]  # é¢„æµ‹æ’åº
    top_k_true = y_true_onehot[order[:k]]
    gains = 2 ** top_k_true - 1
    discounts = np.log2(np.arange(k) + 2)  # ä¿®æ­£discountè®¡ç®—
    return np.sum(gains / discounts)

def ndcg_score_last_timestep(y_true_seq, y_pred_seq, k):
    """ next poi metrics: NDCG score at the last timestep """
    # ç”Ÿæˆç†æƒ³DCG
    y_true_id = y_true_seq[-1]
    y_pred = y_pred_seq[-1]
    num_poi = y_pred.shape[0]

    ideal_true = np.zeros(num_poi)
    if y_true_id < num_poi:
        ideal_true[y_true_id] = 1

    # è®¡ç®—ç†æƒ³æ’åºçš„DCGï¼ˆæœ€ä½³æƒ…å†µï¼‰
    ideal_order = np.argsort(ideal_true)[::-1]
    ideal_gains = 2 ** ideal_true[ideal_order[:k]] - 1
    ideal_discounts = np.log2(np.arange(k) + 2)
    best_dcg = np.sum(ideal_gains / ideal_discounts)

    if best_dcg == 0:
        return 0.0

    # è®¡ç®—å½“å‰DCG
    current_dcg = dcg_score_last_timestep(y_true_seq, y_pred_seq, k)
    return current_dcg / best_dcg

def coverage_at_ks_last_timestep(pred_pois):
    """
    pred_pois: (seq_len, num_poi) çš„é¢„æµ‹æ¦‚ç‡
    return: å­—å…¸ {k: æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„top-k POIç´¢å¼•é›†åˆ}
    """
    last_step_pred = pred_pois[-1]  # å–æœ€åä¸€ä¸ªæ—¶é—´æ­¥
    topk_indices = {
        k: set(np.argpartition(last_step_pred, -k)[-k:])
        for k in [5, 10, 20]
    }
    return topk_indices
